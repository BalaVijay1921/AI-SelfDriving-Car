{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56dd26d5-61cd-4ed0-8c0b-ff8e1ebe11c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from IPython.display import Video, display\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9309fc4-baac-4fbf-acd4-ece5adcddebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img  = r\"C:\\PERSONAL\\Bala\\Bala_MTECH\\3 rd sem\\Internship\\SelfDriving\\Input Images\\solidWhiteCurve.jpg\"\n",
    "output_img = r\"C:\\PERSONAL\\Bala\\Bala_MTECH\\3 rd sem\\Internship\\SelfDriving\\Basic Perception\\Output.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bfaf782-1e38-4117-a49a-cebdd2c53fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_video  = r\"C:\\PERSONAL\\Bala\\Bala_MTECH\\3 rd sem\\Internship\\SelfDriving\\Input Video\\solidWhiteRight.mp4\"\n",
    "output_video = r\"C:\\PERSONAL\\Bala\\Bala_MTECH\\3 rd sem\\Internship\\SelfDriving\\Basic Perception\\Output.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9d5ec36-3d22-4910-b5de-436a5b180908",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Edge Detection\n",
    "def canny(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray, (5,5), 0)\n",
    "    edges = cv2.Canny(blur, 50, 150)\n",
    "    return edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2aa97637-2c1a-4573-8d41-07f77c8e7140",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROI\n",
    "def region_of_interest(image):\n",
    "    h, w = image.shape[:2]\n",
    "    polygon = np.array([[(0,h), (w,h), (w//2, int(h*0.55))]])\n",
    "    \n",
    "    mask = np.zeros_like(image)\n",
    "    cv2.fillPoly(mask, polygon, 255)\n",
    "    return cv2.bitwise_and(image, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f7ce79b-350b-46dd-9ee2-c7b318310ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Line Detection + Averaging\n",
    "def make_coordinates(image, line):\n",
    "    slope, intercept = line\n",
    "    h = image.shape[0]\n",
    "    y1 = h\n",
    "    y2 = int(h*0.6)\n",
    "    x1 = int((y1 - intercept) / slope)\n",
    "    x2 = int((y2 - intercept) / slope)\n",
    "    return np.array([x1,y1,x2,y2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0be64ce4-13a7-4400-b08e-da793ba3cbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract and Average Hough lines\n",
    "def average_slope_intercept(image, lines):\n",
    "    if lines is None:\n",
    "        return []\n",
    "\n",
    "    left = []\n",
    "    right = []\n",
    "\n",
    "    for line in lines:\n",
    "        x1,y1,x2,y2 = line.reshape(4)\n",
    "        slope, intercept = np.polyfit((x1,x2),(y1,y2),1)\n",
    "\n",
    "        if slope < 0:\n",
    "            left.append((slope,intercept))\n",
    "        else:\n",
    "            right.append((slope,intercept))\n",
    "\n",
    "    final = []\n",
    "\n",
    "    if len(left):\n",
    "        left_avg = np.average(left, axis=0)\n",
    "        final.append(make_coordinates(image, left_avg))\n",
    "    if len(right):\n",
    "        right_avg = np.average(right, axis=0)\n",
    "        final.append(make_coordinates(image, right_avg))\n",
    "\n",
    "    return final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3b2800c-f295-4b1f-9ba8-a6a27447365a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lines Display\n",
    "def display_lines(image, lines):\n",
    "    line_img = np.zeros_like(image)\n",
    "\n",
    "    if lines is None or len(lines)==0:\n",
    "        return line_img\n",
    "\n",
    "    for line in lines:\n",
    "        if line is None: continue\n",
    "        x1,y1,x2,y2 = line\n",
    "        cv2.line(line_img,(x1,y1),(x2,y2),(0,255,0),8)\n",
    "\n",
    "    return line_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8dda2a07-31fe-4b05-b0aa-609231a68e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lane Detection Pipeline\n",
    "def pipeline(image):\n",
    "    edges = canny(image)\n",
    "    roi = region_of_interest(edges)\n",
    "\n",
    "    lines = cv2.HoughLinesP(roi, 2, np.pi/180, 20, np.array([]), minLineLength=20, maxLineGap=50)\n",
    "\n",
    "    averaged_lines = average_slope_intercept(image, lines)\n",
    "    line_img = display_lines(image, averaged_lines)\n",
    "    combo = cv2.addWeighted(image, 0.8, line_img, 1, 1)\n",
    "    return combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54482ec1-a1ed-4442-b9a8-cecf41875b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PB exists: True\n",
      "PBTXT exists: True\n",
      "COCO.NAMES exists: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"PB exists:\", os.path.exists(r\"C:\\PERSONAL\\Bala\\Bala_MTECH\\3 rd sem\\Internship\\SelfDriving\\Basic Perception\\Models\\frozen_inference_graph.pb\"))\n",
    "print(\"PBTXT exists:\", os.path.exists(r\"C:\\PERSONAL\\Bala\\Bala_MTECH\\3 rd sem\\Internship\\SelfDriving\\Basic Perception\\Models\\ssd_mobilenet_v3_large_coco_2020_01_14.pbtxt\"))\n",
    "print(\"COCO.NAMES exists:\", os.path.exists(r\"C:\\PERSONAL\\Bala\\Bala_MTECH\\3 rd sem\\Internship\\SelfDriving\\Basic Perception\\Models\\coco.names\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10669d72-0b15-4fca-8ca9-5ec4cb9dd680",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load COCO labels\n",
    "import cv2\n",
    "\n",
    "model = r\"C:\\PERSONAL\\Bala\\Bala_MTECH\\3 rd sem\\Internship\\SelfDriving\\Basic Perception\\Models\\frozen_inference_graph.pb\"\n",
    "config = r\"C:\\PERSONAL\\Bala\\Bala_MTECH\\3 rd sem\\Internship\\SelfDriving\\Basic Perception\\Models\\ssd_mobilenet_v3_large_coco_2020_01_14.pbtxt\"\n",
    "\n",
    "net = cv2.dnn_DetectionModel(model, config)\n",
    "net.setInputSize(320, 320)\n",
    "net.setInputScale(1.0/127.5)\n",
    "net.setInputMean((127.5,127.5,127.5))\n",
    "net.setInputSwapRB(True)\n",
    "\n",
    "with open(r\"C:\\PERSONAL\\Bala\\Bala_MTECH\\3 rd sem\\Internship\\SelfDriving\\Basic Perception\\Models\\coco.names\") as f:\n",
    "    classNames = f.read().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a830e313-78b2-44ac-af9b-35a128622ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81 ['person', 'bicycle', 'car', 'motorbike', 'aeroplane', 'bus', 'train', 'truck', 'boat', 'traffic light']\n"
     ]
    }
   ],
   "source": [
    "print(len(classNames), classNames[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ca22f5a-48e3-4aa6-b67f-2cec669d1f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classIds: [ 3  3  3  3  3  3  3  8  8  3  3  3  3  3  1  3  8 10  1 21 21  3  3  3\n",
      "  3  3  3  3  8  8 21]\n",
      "confs: [0.7326956  0.7057671  0.60839117 0.5900403  0.47754136 0.4477706\n",
      " 0.4436142  0.43373936 0.42951724 0.42778143 0.41681582 0.41553956\n",
      " 0.40002948 0.39970598 0.38649723 0.38631833 0.37126562 0.37102234\n",
      " 0.36325836 0.36025107 0.35616183 0.34825498 0.32615298 0.3247697\n",
      " 0.32331854 0.32227013 0.32138276 0.31230164 0.30374753 0.30189335\n",
      " 0.30006737]\n",
      "boxes: [[184 306  85  46]\n",
      " [103 307  70  46]\n",
      " [283 305  36  28]\n",
      " [ 56 305  28  16]\n",
      " [365 305  22  16]\n",
      " [390 306  24  17]\n",
      " [260 311  38  36]\n",
      " [184 306  85  46]\n",
      " [283 305  36  28]\n",
      " [105 307  41  19]\n",
      " [197 303  61  33]\n",
      " [576 278  21  18]\n",
      " [285 316  27  21]\n",
      " [265 306  32  24]\n",
      " [390 306  24  17]\n",
      " [424 302  23  18]\n",
      " [103 307  70  46]\n",
      " [294 283  15  14]\n",
      " [424 302  23  18]\n",
      " [424 302  23  18]\n",
      " [390 306  24  17]\n",
      " [631 279  18  14]\n",
      " [552 286  19  14]\n",
      " [ 61 310  27  17]\n",
      " [491 298  24  15]\n",
      " [147 304  35  23]\n",
      " [569 279  22  18]\n",
      " [ 34 312  24  11]\n",
      " [390 306  24  17]\n",
      " [576 278  21  18]\n",
      " [491 298  24  15]]\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(r\"C:\\PERSONAL\\Bala\\Bala_MTECH\\3 rd sem\\Internship\\SelfDriving\\Input Images\\solidWhiteCurve.jpg\")\n",
    "\n",
    "classIds, confs, boxes = net.detect(img, confThreshold=0.3)\n",
    "print(\"classIds:\", classIds)\n",
    "print(\"confs:\", confs)\n",
    "print(\"boxes:\", boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2dc8e5d9-228a-4af6-a1ec-3dd67cdaaa8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image Detection\n",
    "def detect_objects(image, conf=0.6):\n",
    "    classIds, confs, boxes = net.detect(image, confThreshold=conf)\n",
    "    objs = []\n",
    "\n",
    "    if len(classIds) != 0:\n",
    "        for classId, confidence, box in zip(classIds.flatten(), confs.flatten(), boxes):\n",
    "            \n",
    "            label = classNames[classId-1]\n",
    "\n",
    "            # âœ… Filter only vehicles\n",
    "            if label not in [\"car\", \"truck\", \"bus\"]:\n",
    "                continue\n",
    "\n",
    "            objs.append((label, float(confidence), box))\n",
    "\n",
    "    return objs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b9b1ac4-3b79-4b69-8e3b-de9aba69b2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Single Image Drawing Boxes\n",
    "def draw_objects(image, objects):\n",
    "    for label, confidence, box in objects:\n",
    "        x, y, w, h = map(int, box)\n",
    "\n",
    "        cv2.rectangle(image, (x, y), (x+w, y+h), (0,255,0), 2)\n",
    "        cv2.putText(image,\n",
    "                    f\"{label} {confidence:.2f}\",\n",
    "                    (x, y-10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.5, (0,255,0), 2)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e138e12-384b-45a8-afed-47760f8ea8e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Saved output to: C:\\PERSONAL\\Bala\\Bala_MTECH\\3 rd sem\\Internship\\SelfDriving\\Basic Perception\\Output.jpg\n"
     ]
    }
   ],
   "source": [
    "#Run on Single Image\n",
    "image = cv2.imread(input_img)\n",
    "\n",
    "objects = detect_objects(image)      # detect\n",
    "result  = draw_objects(image, objects)   # annotate\n",
    "\n",
    "cv2.imwrite(output_img, result)\n",
    "print(\" Saved output to:\", output_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb8b0869-65a7-49f8-afc1-fc2dd74aa4b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('car', 0.7326955795288086, array([184, 306,  85,  46])), ('car', 0.7057670950889587, array([103, 307,  70,  46])), ('car', 0.6083911657333374, array([283, 305,  36,  28]))]\n"
     ]
    }
   ],
   "source": [
    "frame = cv2.imread(r\"C:\\PERSONAL\\Bala\\Bala_MTECH\\3 rd sem\\Internship\\SelfDriving\\Input Images\\solidWhiteCurve.jpg\")  \n",
    "objects = detect_objects(frame)\n",
    "print(objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6742b619-ce82-4ce2-adea-3d90247ae2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Video Object Detection Function\n",
    "def detect_objects(image, conf=0.6):\n",
    "    classIds, confs, boxes = net.detect(image, confThreshold=conf)\n",
    "    objs = []\n",
    "\n",
    "    if len(classIds) != 0:\n",
    "        for classId, confidence, box in zip(classIds.flatten(), confs.flatten(), boxes):\n",
    "            label = classNames[classId - 1]\n",
    "            if label not in [\"car\", \"truck\", \"bus\"]:\n",
    "                continue\n",
    "            objs.append((label, float(confidence), box))\n",
    "    return objs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c6033f1-f49c-40f1-878f-337c1e40f706",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Video Drawing Objects\n",
    "def draw_objects(image, objects):\n",
    "    for label, confidence, box in objects:\n",
    "        x, y, w, h = map(int, box)\n",
    "        cv2.rectangle(image, (x,y),(x+w,y+h),(0,255,0),2)\n",
    "        cv2.putText(image, f\"{label} {confidence:.2f}\",\n",
    "                    (x,y-10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.5,(0,255,0),2)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "19f7a6b5-471a-4376-892c-f2db45195058",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Video Perception \n",
    "def perception_pipeline(frame):\n",
    "    lane_img = pipeline(frame)\n",
    "    objects = detect_objects(frame)\n",
    "    final = annotate_objects(lane_img, objects)\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "354df812-1cb0-4332-99f8-e2ee4da1ab81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video saved: C:\\PERSONAL\\Bala\\Bala_MTECH\\3 rd sem\\Internship\\SelfDriving\\Basic Perception\\Output.mp4\n"
     ]
    }
   ],
   "source": [
    "#Run and Saving Video \n",
    "cap = cv2.VideoCapture(input_video)\n",
    "\n",
    "w = int(cap.get(3))\n",
    "h = int(cap.get(4))\n",
    "fps = cap.get(5) if cap.get(5) > 0 else 30\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "out = cv2.VideoWriter(output_video, fourcc, fps, (w,h))\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    objs = detect_objects(frame)\n",
    "    frame = draw_objects(frame, objs)   \n",
    "\n",
    "    out.write(frame)\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "print(\"Video saved:\", output_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da5787a-7673-4e19-9cd2-ba03eeddc911",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
